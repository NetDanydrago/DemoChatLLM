# üöÄ DemoChatLLM - Cliente Blazor con Chat LLM

Demo presentado en **NetConf 2025 Puebla** que muestra la integraci√≥n de un cliente Blazor WebAssembly con una API ASP.NET Core que expone capacidades de un Large Language Model (LLM) con soporte para ejecuci√≥n de herramientas.

## üìã Descripci√≥n

Este proyecto demuestra una arquitectura completa de chat impulsado por IA:

- **Cliente:** Aplicaci√≥n Blazor WebAssembly (DemoChatLLM.Web) con interfaz de chat interactiva
- **API:** ASP.NET Core Web API (Api.Chat) que sirve como puente hacia servicios LLM (OpenAI, Groq, etc.)
- **Arquitectura:** Implementaci√≥n de vertical slice con separaci√≥n en capas (Proxies, ViewModels, Views)

## üéì Basado en el Curso MCP

Los paquetes NuGet locales utilizados en este proyecto fueron desarrollados en base al curso:

**"MCP para Programadores de C#"**  
üîó [https://devscommunity.net/mcp/](https://devscommunity.net/mcp/)

Este curso ense√±a c√≥mo implementar el Model Context Protocol (MCP) en aplicaciones C# para integrar capacidades avanzadas de IA.

## üèóÔ∏è Arquitectura del Proyecto

```
DemoChatLLM.sln
‚îú‚îÄ‚îÄ Api.Chat/                      # API Backend con endpoints LLM
‚îÇ   ‚îú‚îÄ‚îÄ Program.cs
‚îÇ   ‚îú‚îÄ‚îÄ appsettings.json
‚îÇ   ‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ McpResponseDto.cs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ToolsResultWrapper.cs
‚îÇ   ‚îî‚îÄ‚îÄ Providers/
‚îÇ       ‚îî‚îÄ‚îÄ BlazzingPizzaToolProvider.cs
‚îÇ
‚îú‚îÄ‚îÄ DemoChatLLM.Web/               # Cliente Blazor WebAssembly
‚îÇ   ‚îú‚îÄ‚îÄ Program.cs
‚îÇ   ‚îú‚îÄ‚îÄ wwwroot/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ appsettings.json
‚îÇ   ‚îî‚îÄ‚îÄ Shared/
‚îÇ       ‚îú‚îÄ‚îÄ MainLayout.razor
‚îÇ       ‚îî‚îÄ‚îÄ NavMenu.razor
‚îÇ
‚îú‚îÄ‚îÄ Chat/                          # M√≥dulo Chat (Vertical Slice)
‚îÇ   ‚îú‚îÄ‚îÄ Chat.Proxies/              # Comunicaci√≥n con la API
‚îÇ   ‚îú‚îÄ‚îÄ Chat.ViewModels/           # L√≥gica de presentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ Chat.Views/                # Componentes UI
‚îÇ
‚îú‚îÄ‚îÄ Common/
‚îÇ   ‚îî‚îÄ‚îÄ Entities/                  # DTOs compartidos
‚îÇ       ‚îî‚îÄ‚îÄ Dtos/
‚îÇ           ‚îî‚îÄ‚îÄ ChatMessageDto.cs
‚îÇ
‚îî‚îÄ‚îÄ LocalNugets/                   # Paquetes locales del curso MCP
```

## ‚öôÔ∏è Configuraci√≥n

### Prerrequisitos

- **.NET 10.0 SDK** (o superior)
- **Visual Studio 2022** o **VS Code** con extensi√≥n C#
- **Clave API** de un proveedor LLM (OpenAI, Groq, etc.)

### Paso 1: Configurar la API Backend

1. **Abrir** [Api.Chat/appsettings.json](Api.Chat/appsettings.json)

2. **No es necesario modificar nada** - la configuraci√≥n est√° en el c√≥digo:

```csharp
builder.Services.AddOpenAIProvider(options =>
{
    options.Model = "openai/gpt-oss-120b";
    options.BaseUrl = "https://api.groq.com/openai/v1/";
    options.RelativeEndpoint = "chat/completions";
    options.AuthenticationHeaderValue = "Bearer TU_API_KEY_AQUI";
    options.Temperature = 1;
    options.MaxCompletionTokens = 8192;
});
```

3. **Reemplazar** `TU_API_KEY_AQUI` en [Api.Chat/Program.cs](Api.Chat/Program.cs#L18) con tu clave API:

   - Para **Groq:** Obt√©n tu clave en [https://console.groq.com/keys](https://console.groq.com/keys)
   - Para **OpenAI:** Usa `https://api.openai.com/v1/` como `BaseUrl` y tu clave de OpenAI

### Paso 2: Configurar el Cliente Blazor

1. **Abrir** [DemoChatLLM.Web/wwwroot/appsettings.json](DemoChatLLM.Web/wwwroot/appsettings.json)

2. **Verificar** que la URL de la API coincida con el puerto configurado en la API:

```json
{
  "ChatApiBaseUrl": "https://localhost:7135/",
  "ChatApiRelativeUrl": "chat"
}
```

3. Si el puerto de la API es diferente, actualizar `ChatApiBaseUrl` seg√∫n [Api.Chat/Properties/launchSettings.json](Api.Chat/Properties/launchSettings.json)

### Paso 3: Restaurar Paquetes

Los paquetes locales del curso MCP est√°n en la carpeta `LocalNugets/`. Para restaurarlos:

```bash
dotnet restore
```

## üöÄ Ejecuci√≥n

### Opci√≥n 1: Proyectos M√∫ltiples en Visual Studio

1. **Clic derecho** en la soluci√≥n `DemoChatLLM.sln`
2. Seleccionar **"Configurar proyectos de inicio"**
3. Elegir **"Proyectos de inicio m√∫ltiples"**
4. Configurar:
   - `Api.Chat` ‚Üí **Iniciar**
   - `DemoChatLLM.Web` ‚Üí **Iniciar**
5. Presionar **F5** o hacer clic en **Iniciar**

### Opci√≥n 2: L√≠nea de Comandos

**Terminal 1 - API:**
```bash
cd Api.Chat
dotnet run
```

**Terminal 2 - Cliente Blazor:**
```bash
cd DemoChatLLM.Web
dotnet run
```

### Verificaci√≥n

- **API:** [https://localhost:7135/openapi](https://localhost:7135/openapi)
- **Cliente:** [https://localhost:7036](https://localhost:7036) (o el puerto que asigne Kestrel)

## üéØ Caracter√≠sticas

### Cliente Blazor (DemoChatLLM.Web)
- ‚úÖ Interfaz de chat responsive (mobile-first)
- ‚úÖ Comunicaci√≥n en tiempo real con la API
- ‚úÖ Gesti√≥n de estado con ViewModels
- ‚úÖ Inyecci√≥n de dependencias centralizada

### API Backend (Api.Chat)
- ‚úÖ Endpoints para chat con LLM
- ‚úÖ Soporte para ejecuci√≥n de herramientas (MCP)
- ‚úÖ Integraci√≥n con OpenAI/Groq compatible APIs
- ‚úÖ CORS configurado para desarrollo
- ‚úÖ Provider de ejemplo: BlazzingPizzaToolProvider

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Frontend:** Blazor WebAssembly (.NET 10)
- **Backend:** ASP.NET Core Web API (.NET 10)
- **LLM Client:** Implementaci√≥n custom compatible con OpenAI
- **MCP:** Model Context Protocol para ejecuci√≥n de herramientas
- **Arquitectura:** Vertical Slice con Primary Constructors

## üìö Estructura de Capas

Cada m√≥dulo (ej: `Chat/`) sigue una arquitectura de 3 capas:

1. **Proxies:** Comunicaci√≥n HTTP con la API
   - Interfaces (`IChatProxy`)
   - Implementaciones (`ChatProxy`)
   - DI Container

2. **ViewModels:** L√≥gica de presentaci√≥n y estado
   - Interfaces (`IChatViewModel`)
   - Modelos (`ChatMessageModel`)
   - Adaptadores (`ChatMessageAdapter`)
   - ViewModels (`ChatViewModel`)

3. **Views:** Componentes Blazor
   - P√°ginas Razor (`ChatPage.razor`)
   - Code-behind (`ChatPage.razor.cs`)

## üîß Soluci√≥n de Problemas

### Error de CORS
Si ves errores de CORS en la consola del navegador:
- Verificar que la API est√© ejecut√°ndose
- Confirmar que `app.UseCors()` est√° configurado en [Api.Chat/Program.cs](Api.Chat/Program.cs#L40)

### Error de Conexi√≥n
Si el cliente no se conecta a la API:
- Revisar los puertos en `launchSettings.json` de ambos proyectos
- Actualizar `ChatApiBaseUrl` en el cliente seg√∫n el puerto de la API

### Paquetes NuGet Locales no Encontrados
Si faltan referencias a paquetes del curso MCP:
```bash
dotnet nuget add source ./LocalNugets --name LocalMCP
dotnet restore
```


## üìÑ Licencia

Este proyecto es un demo educativo presentado en el NetConf 2025 Puebla.

## üîó Enlaces Relacionados

- **Curso MCP para C#:** [https://devscommunity.net/mcp/](https://devscommunity.net/mcp/)
- **NetConf 2025 Puebla:** [Evento oficial]
- **Groq Console:** [https://console.groq.com/](https://console.groq.com/)
- **OpenAI Platform:** [https://platform.openai.com/](https://platform.openai.com/)

---

**¬°Desarrollado para NetConf 2025 Puebla! üá≤üáΩ**
